{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee926f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dbca72",
   "metadata": {},
   "source": [
    "## Load, clean, and format CGM Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022a848",
   "metadata": {},
   "source": [
    "Function to load and clean CGM data for one patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7aa2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_load_dexcom(pathname):\n",
    "    \"\"\"\n",
    "    Load and clean a Dexcom CSV file.\n",
    "    \n",
    "    Filters for EGV (Estimated Glucose Values),\n",
    "    renames columns to 'Timestamp' and 'Value',\n",
    "    and adds a 'Source' column labeled 'Dexcom'.\n",
    "    \n",
    "    Parameters:\n",
    "        pathname (str): Path to the Dexcom CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with 'Timestamp', 'Value', and 'Source'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(pathname)\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    df = df[['Timestamp (YYYY-MM-DDThh:mm:ss)', 'Glucose Value (mg/dL)', 'Event Type']]\n",
    "\n",
    "    # Filter to only EGV (Estimated Glucose Values)\n",
    "    df = df[df['Event Type'] == 'EGV']\n",
    "\n",
    "    # Drop the Event Type column\n",
    "    df = df.drop('Event Type', axis=1)\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\n",
    "        'Timestamp (YYYY-MM-DDThh:mm:ss)': 'timestamp',\n",
    "        'Glucose Value (mg/dL)': 'value'\n",
    "    })\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c707a",
   "metadata": {},
   "source": [
    "Iterate over each patient, load their CGM data with clean_and_load_dexcom(), add patient_id column, and concat into one master dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ace9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_dexcom(folder_path):\n",
    "    \"\"\"\n",
    "    Load and combine all Dexcom CSV files (Dexcom_001.csv through Dexcom_016.csv)\n",
    "    from a folder into a single cleaned DataFrame.\n",
    "\n",
    "    Adds a 'patient_id' column to each row.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing the Dexcom CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with 'Timestamp', 'Value', 'Source', and 'patient_id'.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "\n",
    "    for i in range(1, 17):\n",
    "        filename = f\"Dexcom_{i:03d}.csv\"\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        \n",
    "        df = clean_and_load_dexcom(filepath)\n",
    "        df['patient_id'] = i\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76a1a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dexcom_data = load_all_dexcom('data/dexcom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f5c38c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "patient_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "795c4ea9-87cc-4e9f-8fc5-0338b827c8de",
       "rows": [
        [
         "0",
         "2020-02-13 17:23:32",
         "61.0",
         "1"
        ],
        [
         "1",
         "2020-02-13 17:28:32",
         "59.0",
         "1"
        ],
        [
         "2",
         "2020-02-13 17:33:32",
         "58.0",
         "1"
        ],
        [
         "3",
         "2020-02-13 17:38:32",
         "59.0",
         "1"
        ],
        [
         "4",
         "2020-02-13 17:43:31",
         "63.0",
         "1"
        ],
        [
         "5",
         "2020-02-13 17:48:31",
         "67.0",
         "1"
        ],
        [
         "6",
         "2020-02-13 17:53:31",
         "68.0",
         "1"
        ],
        [
         "7",
         "2020-02-13 17:58:31",
         "63.0",
         "1"
        ],
        [
         "8",
         "2020-02-13 18:03:32",
         "59.0",
         "1"
        ],
        [
         "9",
         "2020-02-13 18:08:32",
         "60.0",
         "1"
        ],
        [
         "10",
         "2020-02-13 18:13:32",
         "70.0",
         "1"
        ],
        [
         "11",
         "2020-02-13 18:18:32",
         "86.0",
         "1"
        ],
        [
         "12",
         "2020-02-13 18:23:32",
         "105.0",
         "1"
        ],
        [
         "13",
         "2020-02-13 18:28:31",
         "118.0",
         "1"
        ],
        [
         "14",
         "2020-02-13 18:33:31",
         "127.0",
         "1"
        ],
        [
         "15",
         "2020-02-13 18:38:32",
         "133.0",
         "1"
        ],
        [
         "16",
         "2020-02-13 18:43:32",
         "139.0",
         "1"
        ],
        [
         "17",
         "2020-02-13 18:48:32",
         "143.0",
         "1"
        ],
        [
         "18",
         "2020-02-13 18:53:32",
         "141.0",
         "1"
        ],
        [
         "19",
         "2020-02-13 18:58:32",
         "132.0",
         "1"
        ],
        [
         "20",
         "2020-02-13 19:03:31",
         "122.0",
         "1"
        ],
        [
         "21",
         "2020-02-13 19:08:31",
         "116.0",
         "1"
        ],
        [
         "22",
         "2020-02-13 19:13:32",
         "114.0",
         "1"
        ],
        [
         "23",
         "2020-02-13 19:18:32",
         "113.0",
         "1"
        ],
        [
         "24",
         "2020-02-13 19:23:31",
         "111.0",
         "1"
        ],
        [
         "25",
         "2020-02-13 19:28:31",
         "110.0",
         "1"
        ],
        [
         "26",
         "2020-02-13 19:33:32",
         "110.0",
         "1"
        ],
        [
         "27",
         "2020-02-13 19:38:31",
         "115.0",
         "1"
        ],
        [
         "28",
         "2020-02-13 19:43:32",
         "119.0",
         "1"
        ],
        [
         "29",
         "2020-02-13 19:48:32",
         "123.0",
         "1"
        ],
        [
         "30",
         "2020-02-13 19:53:31",
         "123.0",
         "1"
        ],
        [
         "31",
         "2020-02-13 19:58:31",
         "124.0",
         "1"
        ],
        [
         "32",
         "2020-02-13 20:03:32",
         "123.0",
         "1"
        ],
        [
         "33",
         "2020-02-13 20:08:32",
         "123.0",
         "1"
        ],
        [
         "34",
         "2020-02-13 20:13:32",
         "120.0",
         "1"
        ],
        [
         "35",
         "2020-02-13 20:18:32",
         "117.0",
         "1"
        ],
        [
         "36",
         "2020-02-13 20:23:31",
         "113.0",
         "1"
        ],
        [
         "37",
         "2020-02-13 20:28:31",
         "108.0",
         "1"
        ],
        [
         "38",
         "2020-02-13 20:33:31",
         "104.0",
         "1"
        ],
        [
         "39",
         "2020-02-13 20:38:32",
         "104.0",
         "1"
        ],
        [
         "40",
         "2020-02-13 20:43:31",
         "106.0",
         "1"
        ],
        [
         "41",
         "2020-02-13 20:48:32",
         "104.0",
         "1"
        ],
        [
         "42",
         "2020-02-13 20:53:31",
         "100.0",
         "1"
        ],
        [
         "43",
         "2020-02-13 20:58:31",
         "98.0",
         "1"
        ],
        [
         "44",
         "2020-02-13 21:03:32",
         "95.0",
         "1"
        ],
        [
         "45",
         "2020-02-13 21:08:31",
         "89.0",
         "1"
        ],
        [
         "46",
         "2020-02-13 21:13:32",
         "83.0",
         "1"
        ],
        [
         "47",
         "2020-02-13 21:18:31",
         "82.0",
         "1"
        ],
        [
         "48",
         "2020-02-13 21:23:32",
         "86.0",
         "1"
        ],
        [
         "49",
         "2020-02-13 21:28:32",
         "90.0",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 36898
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-13 17:23:32</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13 17:28:32</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-13 17:33:32</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-13 17:38:32</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-13 17:43:31</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36893</th>\n",
       "      <td>2020-07-24 09:58:05</td>\n",
       "      <td>108.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36894</th>\n",
       "      <td>2020-07-24 10:03:05</td>\n",
       "      <td>108.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36895</th>\n",
       "      <td>2020-07-24 10:08:05</td>\n",
       "      <td>106.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36896</th>\n",
       "      <td>2020-07-24 10:13:05</td>\n",
       "      <td>102.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36897</th>\n",
       "      <td>2020-07-24 10:18:05</td>\n",
       "      <td>98.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36898 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  value  patient_id\n",
       "0      2020-02-13 17:23:32   61.0           1\n",
       "1      2020-02-13 17:28:32   59.0           1\n",
       "2      2020-02-13 17:33:32   58.0           1\n",
       "3      2020-02-13 17:38:32   59.0           1\n",
       "4      2020-02-13 17:43:31   63.0           1\n",
       "...                    ...    ...         ...\n",
       "36893  2020-07-24 09:58:05  108.0          16\n",
       "36894  2020-07-24 10:03:05  108.0          16\n",
       "36895  2020-07-24 10:08:05  106.0          16\n",
       "36896  2020-07-24 10:13:05  102.0          16\n",
       "36897  2020-07-24 10:18:05   98.0          16\n",
       "\n",
       "[36898 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dexcom_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b4f33",
   "metadata": {},
   "source": [
    "## Load, clean, and format Food Log data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da13f1",
   "metadata": {},
   "source": [
    "Function to load and clean food log data for one patient. Retain sugar, time, and searched food columns. \n",
    "\n",
    "Uses regex to find values in 'time' column that aren't formatted as 'hh:mm:ss', and replaces them with the most recent valid time.\n",
    "\n",
    "The searched food column is used over the logged food column because it provides a more accurate description of the item the patient ate. If the value in the searched food column is null, default to logged food column. This could be good if we want to analyze individual meals. On the other hand, maybe we want to aggregate based on popular foods in the 'logged_foods' column instead to get a greater idea of which meals cause which certain changes in glucose levels. Some values in logged foods seem to be relatively general with names like 'standard breakfast', which might support aggregation. But after looking further, it seems that there is still a lot of variability within logged foods, so this might not be achievable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc9208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_load_food_log(pathname):\n",
    "    \"\"\"\n",
    "    Load and clean a food log CSV file.\n",
    "\n",
    "    Fixes malformed time strings by using the previous valid value,\n",
    "    parses mixed-format dates and times robustly,\n",
    "    and returns a cleaned DataFrame with sugar values and food descriptions.\n",
    "\n",
    "    Parameters:\n",
    "        pathname (str): Path to the food log CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with 'Timestamp', 'Value', and 'Food'.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(pathname)\n",
    "\n",
    "    # Extract date and time columns\n",
    "    date_col = df.iloc[:, 0].astype(str)\n",
    "    time_col = df.iloc[:, 1].astype(str)\n",
    "\n",
    "    # Regex pattern for valid HH:MM:SS\n",
    "    time_pattern = re.compile(r\"^\\d{2}:\\d{2}:\\d{2}$\")\n",
    "\n",
    "    # Fix malformed times\n",
    "    fixed_times = []\n",
    "    prev_time = \"00:00:00\"\n",
    "    for t in time_col:\n",
    "        if time_pattern.match(t):\n",
    "            prev_time = t\n",
    "        fixed_times.append(prev_time)\n",
    "\n",
    "    # Parse combined date and fixed time\n",
    "    timestamp_series = pd.to_datetime(date_col + ' ' + fixed_times, errors='coerce')\n",
    "\n",
    "    # Drop rows with unparseable timestamps\n",
    "    df = df[timestamp_series.notna()].copy()\n",
    "    df['timestamp'] = timestamp_series[timestamp_series.notna()]\n",
    "\n",
    "    # Extract sugar value (index 10) and food description (index 7)\n",
    "    df['value'] = pd.to_numeric(df.iloc[:, 10], errors='coerce')\n",
    "    df['food'] = df.iloc[:, 7].astype(str)\n",
    "\n",
    "    return df[['timestamp', 'value', 'food']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00797798",
   "metadata": {},
   "source": [
    "Iterate over each patient, load their food log data with clean_and_load_food_log(), add patient_id column, and concat into one master dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2d5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_food_logs(folder_path):\n",
    "    \"\"\"\n",
    "    Load and combine all Food_Log_0xx.csv files from a folder into one cleaned DataFrame.\n",
    "    \n",
    "    Adds a 'patient_id' column to each row.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing the food log CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with 'Timestamp', 'Value', and 'patient_id'.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "\n",
    "    for i in range(1, 17):\n",
    "        filename = f\"Food_Log_{i:03d}.csv\"\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "\n",
    "        df = clean_and_load_food_log(filepath)\n",
    "        df['patient_id'] = i\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c52abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_log_data = load_all_food_logs('data/food_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb15f9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "food",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "patient_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e039017c-1b23-4912-960e-1c88f9731a22",
       "rows": [
        [
         "0",
         "2020-02-13 18:00:00",
         "1.7",
         "Strawberry Smoothie",
         "1"
        ],
        [
         "1",
         "2020-02-13 20:30:00",
         "0.0",
         "chicken leg",
         "1"
        ],
        [
         "2",
         "2020-02-13 20:30:00",
         "1.2",
         "Asparagus",
         "1"
        ],
        [
         "3",
         "2020-02-14 07:10:00",
         null,
         "(Natrel) Lactose Free 2% Partly Skimmed Milk",
         "1"
        ],
        [
         "4",
         "2020-02-14 07:10:00",
         null,
         "(Kellogg's) Frosted Flakes, Cereal",
         "1"
        ],
        [
         "5",
         "2020-02-14 09:38:00",
         null,
         "(Giant) Breakfast Blend, Trail Mix",
         "1"
        ],
        [
         "6",
         "2020-02-14 12:38:00",
         null,
         "Spinach And Strawberry Salad",
         "1"
        ],
        [
         "7",
         "2020-02-14 12:38:00",
         null,
         "Large Egg",
         "1"
        ],
        [
         "8",
         "2020-02-14 19:30:00",
         null,
         "(Smoothie King) Acai Adventure Smoothie",
         "1"
        ],
        [
         "9",
         "2020-02-14 20:00:00",
         null,
         "(Trader Joe's) Macaroni and Cheese",
         "1"
        ],
        [
         "10",
         "2020-02-14 20:00:00",
         null,
         "Coconut Shrimp",
         "1"
        ],
        [
         "11",
         "2020-02-15 07:30:00",
         null,
         "Spinach Smoothie",
         "1"
        ],
        [
         "12",
         "2020-02-15 11:02:00",
         null,
         "(Giant) Breakfast Blend, Trail Mix",
         "1"
        ],
        [
         "13",
         "2020-02-15 12:38:00",
         null,
         "Spinach And Strawberry Salad",
         "1"
        ],
        [
         "14",
         "2020-02-15 12:38:00",
         null,
         "Large Egg",
         "1"
        ],
        [
         "15",
         "2020-02-15 15:30:00",
         null,
         "Babybel Cheese",
         "1"
        ],
        [
         "16",
         "2020-02-15 15:35:00",
         null,
         "(Giant) Breakfast Blend, Trail Mix",
         "1"
        ],
        [
         "17",
         "2020-02-15 20:30:00",
         null,
         "Bourbon Chicken",
         "1"
        ],
        [
         "18",
         "2020-02-15 20:30:00",
         null,
         "Rice",
         "1"
        ],
        [
         "19",
         "2020-02-15 20:30:00",
         null,
         "Shrimp",
         "1"
        ],
        [
         "20",
         "2020-02-15 20:30:00",
         null,
         "Cabbage",
         "1"
        ],
        [
         "21",
         "2020-02-16 07:00:00",
         null,
         "(Natrel) Lactose Free 2% Partly Skimmed Milk",
         "1"
        ],
        [
         "22",
         "2020-02-16 07:00:00",
         null,
         "(Kellogg's) Frosted Flakes, Cereal",
         "1"
        ],
        [
         "23",
         "2020-02-16 08:15:00",
         null,
         "(Giant) Breakfast Blend, Trail Mix",
         "1"
        ],
        [
         "24",
         "2020-02-16 08:49:00",
         null,
         "Hot Chocolate",
         "1"
        ],
        [
         "25",
         "2020-02-16 11:56:00",
         null,
         "(Skinny Pop) Popcorn, Sweet & Salty Kettle",
         "1"
        ],
        [
         "26",
         "2020-02-16 12:15:00",
         null,
         "Bourbon Chicken",
         "1"
        ],
        [
         "27",
         "2020-02-16 12:15:00",
         null,
         "Shrimp",
         "1"
        ],
        [
         "28",
         "2020-02-16 21:10:00",
         null,
         "Chai Tea",
         "1"
        ],
        [
         "29",
         "2020-02-17 06:42:00",
         null,
         "Maple Brown Sugar Oatmeal",
         "1"
        ],
        [
         "30",
         "2020-02-17 12:30:00",
         null,
         "(Just Salad) Salad Topping, Dried Cranberries",
         "1"
        ],
        [
         "31",
         "2020-02-17 12:30:00",
         null,
         "Chicken Nuggets",
         "1"
        ],
        [
         "32",
         "2020-02-17 21:00:00",
         null,
         "Kale Salad",
         "1"
        ],
        [
         "33",
         "2020-02-17 21:00:00",
         null,
         "Pizza",
         "1"
        ],
        [
         "34",
         "2020-02-17 21:56:00",
         null,
         "Oreo Cookies",
         "1"
        ],
        [
         "35",
         "2020-02-18 06:20:00",
         null,
         "(Natrel) Lactose Free 2% Partly Skimmed Milk",
         "1"
        ],
        [
         "36",
         "2020-02-18 06:20:00",
         null,
         "(Kellogg's) Frosted Flakes, Cereal",
         "1"
        ],
        [
         "37",
         "2020-02-18 11:00:00",
         null,
         "Muffin",
         "1"
        ],
        [
         "38",
         "2020-02-18 11:45:00",
         null,
         "Grilled Chicken Wrap",
         "1"
        ],
        [
         "39",
         "2020-02-18 01:40:00",
         null,
         "Kale Smoothie",
         "1"
        ],
        [
         "40",
         "2020-02-18 22:00:00",
         null,
         "Ranch Wings",
         "1"
        ],
        [
         "41",
         "2020-02-19 11:00:00",
         null,
         "(Smoothie King) Acai Adventure Smoothie",
         "1"
        ],
        [
         "42",
         "2020-02-19 15:30:00",
         null,
         "Lemon Loaf",
         "1"
        ],
        [
         "43",
         "2020-02-19 18:00:00",
         null,
         "Turkey Slider",
         "1"
        ],
        [
         "44",
         "2020-02-19 20:00:00",
         null,
         "Chicken and Rice",
         "1"
        ],
        [
         "45",
         "2020-02-20 07:37:00",
         null,
         "Green Smoothie",
         "1"
        ],
        [
         "46",
         "2020-02-20 07:37:00",
         null,
         "Bagel",
         "1"
        ],
        [
         "47",
         "2020-02-20 12:30:00",
         null,
         "Salad",
         "1"
        ],
        [
         "48",
         "2020-02-20 13:00:00",
         null,
         "Hot Chocolate",
         "1"
        ],
        [
         "49",
         "2020-02-20 12:30:00",
         null,
         "Babybel Cheese",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1421
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>food</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-13 18:00:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Strawberry Smoothie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13 20:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chicken leg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-13 20:30:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Asparagus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-14 07:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(Natrel) Lactose Free 2% Partly Skimmed Milk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-14 07:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(Kellogg's) Frosted Flakes, Cereal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>2020-02-26 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>2020-02-27 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>2020-02-27 00:00:00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>nan</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>2020-02-27 00:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>2020-02-28 00:00:00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>nan</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1421 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp  value                                          food  \\\n",
       "0    2020-02-13 18:00:00    1.7                           Strawberry Smoothie   \n",
       "1    2020-02-13 20:30:00    0.0                                   chicken leg   \n",
       "2    2020-02-13 20:30:00    1.2                                     Asparagus   \n",
       "3    2020-02-14 07:10:00    NaN  (Natrel) Lactose Free 2% Partly Skimmed Milk   \n",
       "4    2020-02-14 07:10:00    NaN            (Kellogg's) Frosted Flakes, Cereal   \n",
       "...                  ...    ...                                           ...   \n",
       "1416 2020-02-26 00:00:00    0.0                                           nan   \n",
       "1417 2020-02-27 00:00:00    1.0                                           nan   \n",
       "1418 2020-02-27 00:00:00    3.9                                           nan   \n",
       "1419 2020-02-27 00:00:00   11.0                                           nan   \n",
       "1420 2020-02-28 00:00:00    5.6                                           nan   \n",
       "\n",
       "      patient_id  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "1416          16  \n",
       "1417          16  \n",
       "1418          16  \n",
       "1419          16  \n",
       "1420          16  \n",
       "\n",
       "[1421 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f63d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
